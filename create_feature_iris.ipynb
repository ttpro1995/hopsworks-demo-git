{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fd8c6ee5ac8>"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>4</td><td>application_1603101301249_0016</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://resourcemanager.service.consul:8088/proxy/application_1603101301249_0016/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-28-187.us-east-2.compute.internal:8042/node/containerlogs/container_e02_1603101301249_0016_01_000001/mewo_project__ttpro199\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "path = \"hdfs:///Projects/mewo_project/RawDataset/Iris.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_name_lower_case(df):\n",
    "    new_col_name = [item.lower() for item in df.columns]\n",
    "    new_df = df\n",
    "    for old_col, new_col in zip(df.columns, new_col_name):\n",
    "        new_df = new_df.withColumnRenamed(old_col, new_col)\n",
    "        print(\"rename from \", old_col, new_col)\n",
    "    return new_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Id='1', SepalLengthCm='5.1', SepalWidthCm='3.5', PetalLengthCm='1.4', PetalWidthCm='0.2', Species='Iris-setosa')"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rename from  Id id\n",
      "rename from  SepalLengthCm sepallengthcm\n",
      "rename from  SepalWidthCm sepalwidthcm\n",
      "rename from  PetalLengthCm petallengthcm\n",
      "rename from  PetalWidthCm petalwidthcm\n",
      "rename from  Species species"
     ]
    }
   ],
   "source": [
    "df_lower = column_name_lower_case(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id='1', sepallengthcm='5.1', sepalwidthcm='3.5', petallengthcm='1.4', petalwidthcm='0.2', species='Iris-setosa')"
     ]
    }
   ],
   "source": [
    "df_lower.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id='1')"
     ]
    }
   ],
   "source": [
    "df_id = df_lower.select(\"id\")\n",
    "df_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hops import featurestore\n",
    "# featurestore.create_featuregroup(df_lower, \"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing descriptive statistics for : iris_id_only, version: 1\n",
      "computing feature correlation for: iris_id_only, version: 1\n",
      "Could not compute feature correlation for: iris_id_only, version: 1, set the optional argument feature_correlation=False to skip this step,\n",
      " error: The provided spark dataframe does not contain any numeric columns. Cannot compute feature correlation on categorical columns. The numeric datatypes are: ['bigint', 'decimal', 'integer', 'int', 'double', 'long', 'float', 'short'] and the number of numeric datatypes in the dataframe is: 0 ([])\n",
      "computing feature histograms for: iris_id_only, version: 1\n",
      "computing cluster analysis for: iris_id_only, version: 1\n",
      "Could not compute cluster analysis for: iris_id_only, version: 1, set the optional argument cluster_analysis=False to skip this step,\n",
      " error: The provided spark dataframe does not contain any numeric columns. Cannot compute cluster analysis with k-means on categorical columns. The numeric datatypes are: ['bigint', 'decimal', 'integer', 'int', 'double', 'long', 'float', 'short'] and the number of numeric datatypes in the dataframe is: 0 ([])\n",
      "Registering feature metadata...\n",
      "Registering feature metadata... [COMPLETE]\n",
      "Writing feature data to offline feature group (Hive)...\n",
      "Running sql: use mewo_project_featurestore against offline feature store\n",
      "Writing feature data to offline feature group (Hive)... [COMPLETE]\n",
      "Feature group created successfully"
     ]
    }
   ],
   "source": [
    "from hops import featurestore\n",
    "featurestore.create_featuregroup(df_id, \"iris_id_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Found the feature with name 'id' in more than one of the featuregroups of the featurestore: 'mewo_project_featurestore', please specify the optional argument 'featuregroup=', the matched featuregroups were: iris_1,iris_id_only_1\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.6/site-packages/hops/featurestore.py\", line 317, in get_feature\n",
      "    jdbc_args=jdbc_args, online=online)\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 412, in _do_get_feature\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 30, in create_logical_plan\n",
      "    self._feature_query()\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 75, in _feature_query\n",
      "    featuregroups_parsed.values())\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 64, in _find_feature\n",
      "    featuregroups_matched_str))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureNameCollisionError: Found the feature with name 'id' in more than one of the featuregroups of the featurestore: 'mewo_project_featurestore', please specify the optional argument 'featuregroup=', the matched featuregroups were: iris_1,iris_id_only_1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hops import featurestore\n",
    "featurestore.get_feature('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use mewo_project_featurestore against offline feature store\n",
      "Logical query plan for getting 1 feature from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT id FROM iris_1 against offline feature store"
     ]
    }
   ],
   "source": [
    "from hops import featurestore\n",
    "df_get_id = featurestore.get_feature('id', featuregroup=\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "| 15|\n",
      "| 16|\n",
      "| 17|\n",
      "| 18|\n",
      "| 19|\n",
      "| 20|\n",
      "+---+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "df_get_id.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Found the feature with name 'id' in more than one of the featuregroups of the featurestore: 'mewo_project_featurestore', please specify the optional argument 'featuregroup=', the matched featuregroups were: iris_1,iris_id_only_1\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.6/site-packages/hops/featurestore.py\", line 368, in get_features\n",
      "    online=online)\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 613, in _do_get_features\n",
      "    logical_query_plan.create_logical_plan()\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 32, in create_logical_plan\n",
      "    self._features_query()\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/logical_query_plan.py\", line 145, in _features_query\n",
      "    featuregroups_parsed.values())\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.6/site-packages/hops/featurestore_impl/query_planner/query_planner.py\", line 64, in _find_feature\n",
      "    featuregroups_matched_str))\n",
      "hops.featurestore_impl.exceptions.exceptions.FeatureNameCollisionError: Found the feature with name 'id' in more than one of the featuregroups of the featurestore: 'mewo_project_featurestore', please specify the optional argument 'featuregroup=', the matched featuregroups were: iris_1,iris_id_only_1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_get_id = featurestore.get_features([\"id\", \"sepalwidthcm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "get_features() got an unexpected keyword argument 'featuregroup'\n",
      "Traceback (most recent call last):\n",
      "TypeError: get_features() got an unexpected keyword argument 'featuregroup'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_get_id = featurestore.get_features([\"id\", \"sepalwidthcm\"], featuregroup=\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use mewo_project_featurestore against offline feature store\n",
      "Logical query plan for getting 2 features from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT petalwidthcm, sepalwidthcm FROM iris_1 against offline feature store"
     ]
    }
   ],
   "source": [
    "df_2 = featurestore.get_features([\"petalwidthcm\", \"sepalwidthcm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|petalwidthcm|sepalwidthcm|\n",
      "+------------+------------+\n",
      "|         0.2|         3.5|\n",
      "|         0.2|         3.0|\n",
      "|         0.2|         3.2|\n",
      "|         0.2|         3.1|\n",
      "|         0.2|         3.6|\n",
      "|         0.4|         3.9|\n",
      "|         0.3|         3.4|\n",
      "|         0.2|         3.4|\n",
      "|         0.2|         2.9|\n",
      "|         0.1|         3.1|\n",
      "|         0.2|         3.7|\n",
      "|         0.2|         3.4|\n",
      "|         0.1|         3.0|\n",
      "|         0.1|         3.0|\n",
      "|         0.2|         4.0|\n",
      "|         0.4|         4.4|\n",
      "|         0.4|         3.9|\n",
      "|         0.3|         3.5|\n",
      "|         0.3|         3.8|\n",
      "|         0.3|         3.8|\n",
      "+------------+------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
